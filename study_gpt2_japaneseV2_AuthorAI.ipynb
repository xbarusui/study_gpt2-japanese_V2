{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "study_gpt2_japaneseV2_AuthorAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1ONJC71hmOw4bXDhlocEsLDNp9tBYB30C",
      "authorship_tag": "ABX9TyPryZpIK92t+wxM60pyHF38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xbarusui/study_gpt2-japanese_V2/blob/main/study_gpt2_japaneseV2_AuthorAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5AoNh8gggcC"
      },
      "source": [
        "# **作家AI の文章学習・生成**\n",
        "\n",
        "メニュー\n",
        "\n",
        "*   1.前準備(googleドライブ)\n",
        "*   2.前準備(モジュールインストール)\n",
        "*   3.作家AI学習（学習不要な場合はスキップできます）\n",
        "*   4.作家AI文章生成\n",
        "\n",
        "利用方法\n",
        "\n",
        "*   作家AIを作り文章生成させる場合は、<font color= \"blue\">**1-4 の順に**</font>実行してください\n",
        "*   とりあえず文章生成を試したい場合は、<font color= \"blue\"> **1,3,4 の順に**</font> 実行して、Default で文章を生成してください\n",
        "*   学習させると作家AI はgoogleドライブに1-10の番号で格納されます\n",
        "*   作成済みの作家AIを利用する場合も、 <font color= \"blue\">**1,3,4 の順に**</font> 実行してください\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEguJMjixy_"
      },
      "source": [
        "# **<font color= \"red\">1.前準備(googleドライブ)</font>**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk3rPez-i1sl",
        "cellView": "form"
      },
      "source": [
        "#@title googleドライブに接続して gpt2work というフォルダを作成\n",
        "\n",
        "#@markdown **<font color= \"blue\">左のセルを実行してください</font>**\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p '/content/drive/My Drive/gpt2work/'\n",
        "%cd '/content/drive/My Drive/gpt2work/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JlZ62nVvcrq"
      },
      "source": [
        "## 上記の説明\n",
        "\n",
        "1．「Googleドライブに接続してgpt2workというフォルダを作成」というセルを実行すると、URLと入力欄が表示されます。\n",
        "\n",
        "![Googleドライブ認証](https://github.com/xbarusui/study_gpt2-japanese_V2/blob/main/authimage1.png?raw=true)\n",
        "\n",
        "2．青いURLをクリックすると、新しいタブが開いて、colabと連携するアカウントを聞かれます（聞かれなかった場合、次に進んで下さい）\n",
        "\n",
        "![アカウントの選択](https://github.com/xbarusui/study_gpt2-japanese_V2/blob/main/authimage2.png?raw=true)\n",
        "\n",
        "3．「このアプリをGoogleからダウンロードしたことをご確認ください」と出ますので確認の上、「ログイン」を選択してください。\n",
        "\n",
        "![代替テキスト](https://github.com/xbarusui/study_gpt2-japanese_V2/blob/main/authimage3.png?raw=true)\n",
        "\n",
        "4．許可すると、認証コードの横にコピーボタンが表示されますので、コピーボタンをクリックして下さい。\n",
        "\n",
        "![認証コード](https://github.com/xbarusui/study_gpt2-japanese_V2/blob/main/authimage4.png?raw=true)\n",
        "\n",
        "5．colabの画面に戻ってきて、URLの下の入力欄にカーソルを合わせて、「Ctrl+V」で貼り付けて下さい。文字列は・で表示されます。\n",
        "\n",
        "![認証コード貼り付け](https://github.com/xbarusui/study_gpt2-japanese_V2/blob/main/authimage5.png?raw=true)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWuaqqlIyNrN"
      },
      "source": [
        "# **<font color= \"red\">2.前準備(モジュールインストール)</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhcO47ppe_5G",
        "cellView": "form"
      },
      "source": [
        "#@title 学習済みモデルと周辺モジュールインストール\n",
        "\n",
        "#@markdown **<font color= \"blue\">左のセルを実行してください</font>**\n",
        "\n",
        "\n",
        "# ディレクトリ移動\n",
        "%cd '/content/drive/My Drive/gpt2work/'\n",
        "\n",
        "!git clone https://github.com/rinnakk/japanese-pretrained-models\n",
        "%cd japanese-pretrained-models\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Huggingface Datasetsのインストール\n",
        "!pip install datasets==1.2.1\n",
        "\n",
        "# Sentencepieceのインストール\n",
        "!pip install sentencepiece==0.1.91\n",
        "\n",
        "# 初めての場合は、gpt2work以下に下のフォルダがないか確認し、無ければモジュールをgithubダウンロード\n",
        "import os\n",
        "path = 'study_gpt2-japanese_V2'\n",
        "is_dir = os.path.isdir(path)\n",
        "\n",
        "if is_dir is False:\n",
        "  !git clone https://github.com/xbarusui/study_gpt2-japanese_V2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_UrG5CkBrv4"
      },
      "source": [
        "# **<font color= \"red\">3.作家AI学習（学習不要な場合はスキップできます）</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odriXTSeRpX0",
        "cellView": "form"
      },
      "source": [
        "#@title 学習させたいテキストファイルをUPLOADする\n",
        "#@markdown **<font color= \"blue\">左のセルを実行して、出てくるウィンドウで学習させたい文章のテキストをアップロードしてください</font>**\n",
        "\n",
        "#@markdown 注1.テキストはUTF-8形式でないと読み込めません\n",
        "\n",
        "#@markdown 注2.既に同名テキストが格納してある場合、ファイル名が(1)のように連番になって上書きせずにアップロードされますので、ご注意ください\n",
        "\n",
        "\n",
        "%cd '/content/drive/My Drive/gpt2work/'\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!ls -l | grep .txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkwfeewOgjBW",
        "cellView": "form"
      },
      "source": [
        "#@title パラメータ設定後に学習開始\n",
        "#@markdown **<font color= \"blue\">下にある3パラメータを設定してから、左のセルを実行してください</font>**\n",
        "\n",
        "%cd '/content/drive/My Drive/gpt2work/'\n",
        "\n",
        "#@markdown **<font color= \"blue\"> 1.学習結果を格納するフォルダをドロップダウンから選択してください</font>**\n",
        "\n",
        "#@markdown 選択した番号のフォルダに作家AIが格納されます\n",
        "\n",
        "authormodel = \"1\" #@param [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
        "\n",
        "#@markdown \n",
        "\n",
        "savefolder = authormodel + \"/\"\n",
        "\n",
        "#@markdown **<font color= \"blue\"> 2.アップロードしたテキスト名を入力してください</font>**\n",
        "\n",
        "#@markdown 同名ファイルをアップロードしている場合、名称が連番になるので最新のテキスト名を指定してください\n",
        "\n",
        "upload_file = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown **<font color= \"blue\"> 3.何エポック学習するかを数字で設定してください</font>**\n",
        "\n",
        "#@markdown エポックというのは訓練データを学習する単位になります。初期値は 30 ですが、それ以上学習させると精度が上がります。\n",
        "\n",
        "#@markdown 簡単に利用するだけなら 30-300 の範囲で1時間程度学習させるくらいで十分ではないかと思います。\n",
        "\n",
        "num_train_epochs = 30  #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "# ファインチューニングの実行\n",
        "!python study_gpt2-japanese_V2/gpt2japanese_study.py \\\n",
        "    --model_name_or_path=rinna/japanese-gpt2-xsmall \\\n",
        "    --train_file={upload_file} \\\n",
        "    --validation_file={upload_file} \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --num_train_epochs={num_train_epochs} \\\n",
        "    --save_steps=5000 \\\n",
        "    --save_total_limit=3 \\\n",
        "    --per_device_train_batch_size=1 \\\n",
        "    --per_device_eval_batch_size=1 \\\n",
        "    --output_dir={savefolder} \\\n",
        "    --use_fast_tokenizer=False \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEfy32CjCY_h"
      },
      "source": [
        "# **<font color= \"red\">4.作家AI文章生成</font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY8CpSnybc9I",
        "cellView": "form"
      },
      "source": [
        "%cd '/content/drive/My Drive/gpt2work/'\n",
        "#@title パラメータ設定後に文章生成\n",
        "#@markdown **<font color= \"blue\">下にある4パラメータを設定してから、左のセルを実行してください</font>**\n",
        "\n",
        "\n",
        "#@markdown **<font color= \"blue\"> 1.作家AIのモデルをドロップダウンから選択してください</font>**\n",
        "\n",
        "#@markdown Default を選択した場合は初期の学習済みモデルを利用し、数字を選択した場合は上で学習した番号に格納された作家AIを利用します\n",
        "\n",
        "authormodel = \"Default\" #@param [\"Default\", \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
        "\n",
        "#@markdown \n",
        "\n",
        "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
        "\n",
        "if authormodel == \"Default\" :\n",
        "  # ライブラリをインポートします。\n",
        "  # 学習済みモデルをダウンロードします。\n",
        "  savefolder = \"rinna/japanese-gpt2-xsmall\"\n",
        "else:\n",
        "  savefolder = authormodel + \"/\"\n",
        "\n",
        "#@markdown **<font color= \"blue\"> 2.書かせる文章の最初の部分を記載してください</font>**\n",
        "\n",
        "#@markdown 最初の文章が長い方が出力される文章は長くなる傾向にあります\n",
        "\n",
        "noveltext = \"\\u3053\\u3093\\u306B\\u3061\\u306F\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown \n",
        "\n",
        "#@markdown **<font color= \"blue\"> 3.出力文字数を指定してください</font>**\n",
        "\n",
        "#@markdown モデルや入力された文章によっては出力文字数は半分くらいに短くなることもあります\n",
        "\n",
        "novellength = 128  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown \n",
        "\n",
        "#@markdown **<font color= \"blue\"> 4.何回生成するかを選択してください</font>**\n",
        "\n",
        "#@markdown 回数が多いほど生成時間は長くなります\n",
        "\n",
        "novelseq =   5#@param {type:\"number\"}\n",
        "\n",
        "\n",
        "# トークナイザーとモデルの準備\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-xsmall\")\n",
        "model = AutoModelForCausalLM.from_pretrained(savefolder)\n",
        "\n",
        "# 生成された文章を表示します。\n",
        "print(\"冒頭の文章\")\n",
        "print(\"----------------------------------------\")\n",
        "print(noveltext)\n",
        "print(\"----------------------------------------\")\n",
        "\n",
        "# 推論\n",
        "input = tokenizer.encode( noveltext , return_tensors=\"pt\")\n",
        "output = model.generate(input, do_sample=True, max_length=novellength, num_return_sequences=novelseq,top_k=0,min_length=int(novellength/2))\n",
        "# 出力されたコードを文章に戻します。\n",
        "DecodedOutput = tokenizer.batch_decode(output)\n",
        "\n",
        "for j in range(novelseq):\n",
        "  print(\"--- AI生成文章\" + str(j+1) + \"回目 ---\")\n",
        "  i = 0\n",
        "  while i < len(DecodedOutput[j]):\n",
        "    print(DecodedOutput[j].replace('</s>','')[i:i+80]) \n",
        "    i = i+80\n",
        "  print(\"----------------------------------------\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}